{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs: How To Implement A Basic RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In, Clean, And Split The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data and split into training and test set\n",
    "# NOTE: we are NOT cleaning the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "messages = pd.read_csv('C:\\\\Users\\\\Yauheni_Leaniuk\\\\Documents\\\\Python\\\\Data_Engineer\\\\Advanced NLP Python for ML\\\\data\\\\spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "labels = np.where(messages['label'] == 'spam', 1, 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text'],\n",
    "                                                    labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data For Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.2.1-cp39-cp39-win_amd64.whl (2.8 MB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-win_amd64.whl (213 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras) (1.20.2)\n",
      "Installing collected packages: pyyaml, h5py, keras\n",
      "Successfully installed h5py-3.2.1 keras-2.4.3 pyyaml-5.4.1\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Install keras\n",
    "!pip install -U keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.5.0-cp39-cp39-win_amd64.whl (422.6 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\yauheni_leaniuk\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.17.0)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Using cached grpcio-1.34.1-cp39-cp39-win_amd64.whl (2.9 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Using cached h5py-3.1.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting tensorboard~=2.5\n",
      "  Using cached tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.30.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=48cf4ff5cf660c670a9726ccdf5e1bfd67717cc43c90c4bc8d5dcd75abf96d5a\n",
      "  Stored in directory: c:\\users\\yauheni_leaniuk\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.2.1\n",
      "    Uninstalling h5py-3.2.1:\n",
      "      Successfully uninstalled h5py-3.2.1\n",
      "Successfully installed absl-py-0.12.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 opt-einsum-3.3.0 tensorboard-2.5.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\yauheni_leaniuk\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools we will need from keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use that tokenizer to transform the text messages in the training and test sets\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[115,\n",
       " 17,\n",
       " 96,\n",
       " 266,\n",
       " 243,\n",
       " 1659,\n",
       " 18,\n",
       " 1435,\n",
       " 2561,\n",
       " 2562,\n",
       " 2563,\n",
       " 512,\n",
       " 1977,\n",
       " 2564,\n",
       " 72,\n",
       " 3,\n",
       " 16,\n",
       " 202,\n",
       " 4,\n",
       " 292,\n",
       " 412,\n",
       " 175,\n",
       " 27,\n",
       " 663,\n",
       " 164]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# What do these sequences look like?\n",
    "X_train_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences so each sequence is the same length\n",
    "X_train_seq_padded = pad_sequences(X_train_seq, 50)\n",
    "X_train_seq_padded = pad_sequences(X_test_seq, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   20,    9,  276],\n",
       "       [ 325,    8, 1926, ..., 1926,  744,  503],\n",
       "       [   0,    0,    0, ...,   10,    9,  985],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,  289,  546],\n",
       "       [   0,    0,    0, ...,   15,   11,  446],\n",
       "       [   0,    0,    0, ...,   50,  255,  225]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# What do these padded sequences look like?\n",
    "X_train_seq_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tools needed from keras and define functions to calculate recall and precision\n",
    "import keras.backend as K\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_6 (Embedding)      (None, None, 32)          253440    \n_________________________________________________________________\ndense_2 (Dense)              (None, None, 32)          1056      \n_________________________________________________________________\ndense_3 (Dense)              (None, None, 1)           33        \n=================================================================\nTotal params: 254,529\nTrainable params: 254,529\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Construct a simple RNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(tokenizer.index_word) + 1, 32))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the RNN model\n",
    "history = model.fit(X_train_seq_padded, y_train, \n",
    "                    batch_size=32, epochs=10,\n",
    "                    validation_data=(X_test_seq_padded, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd01e315a83a4e53ed53959f6fe154dabac6161a453eccd2e252f6243041d5985d2",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "1e315a83a4e53ed53959f6fe154dabac6161a453eccd2e252f6243041d5985d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}