{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec: How To Prep Document Vectors For Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data, clean it, split it into train/test, and then train a doc2vec model\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('C:\\\\Users\\\\Yauheni_Leaniuk\\\\Documents\\\\Python\\\\Data_Engineer\\\\Advanced NLP Python for ML\\\\data\\\\spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)\n",
    "\n",
    "tagged_docs_tr = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]\n",
    "\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs_tr,\n",
    "                                  vector_size=50,\n",
    "                                  window=2,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1.3766643e-02,  1.7499788e-02,  1.3541077e-02,  1.3780495e-03,\n",
       "       -6.4376676e-03, -1.9597791e-02,  1.9648688e-02,  2.4082037e-02,\n",
       "       -5.7258897e-02, -8.9304643e-03,  1.7031122e-04, -4.4385429e-02,\n",
       "        1.4773357e-02, -2.1441039e-04, -9.7018816e-03,  1.5791506e-02,\n",
       "        1.8797398e-02, -1.1057716e-02, -3.1536788e-02, -2.8113209e-02,\n",
       "        2.3679864e-02,  3.3702336e-02,  5.6755405e-02,  1.7633726e-03,\n",
       "        1.9738114e-02,  3.2318349e-03, -2.0592045e-02, -8.8183273e-04,\n",
       "       -4.1750010e-02, -1.8873543e-03,  4.4262866e-05, -6.0080597e-03,\n",
       "        7.6620933e-03,  6.1167362e-03, -1.7966343e-02,  3.2721382e-02,\n",
       "        2.0861464e-02, -4.2716518e-05,  1.3422815e-02, -2.3409529e-02,\n",
       "        4.1234590e-02, -5.2222074e-03, -1.9578291e-03, -6.7260209e-03,\n",
       "        4.7419298e-02,  2.2291460e-03, -7.6893535e-03, -3.7777390e-02,\n",
       "       -2.3205285e-03,  2.0081038e-02], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# What does a document vector look like again?\n",
    "d2v_model.infer_vector(['convert', 'words', 'to', 'vectors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we prepare these vectors to be used in a machine learning model?\n",
    "vectors = [[d2v_model.infer_vector(words)] for words in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([-0.02649028,  0.04117239, -0.01602423, -0.00127124,  0.04570913,\n",
       "         0.00699414, -0.04605034,  0.03874381, -0.10007126, -0.00664009,\n",
       "         0.03163491, -0.00197323, -0.0013985 ,  0.02217884,  0.00015932,\n",
       "         0.00496585,  0.08104873,  0.01852599, -0.02621183, -0.02167246,\n",
       "         0.01391414,  0.05509588,  0.08763269, -0.03599947,  0.00699032,\n",
       "         0.01829489, -0.05681949, -0.03835789, -0.00284678, -0.05480478,\n",
       "         0.01475316, -0.00643213, -0.02554857,  0.02860778,  0.02379835,\n",
       "         0.0921509 , -0.03006966,  0.03991802, -0.01023117, -0.03477583,\n",
       "         0.07384854,  0.02262645,  0.01711992,  0.00421738,  0.06806121,\n",
       "         0.06054883,  0.02302586, -0.04033442, -0.02367729,  0.04790845],\n",
       "       dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "vectors[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd01e315a83a4e53ed53959f6fe154dabac6161a453eccd2e252f6243041d5985d2",
   "display_name": "Python 3.9.4 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "1e315a83a4e53ed53959f6fe154dabac6161a453eccd2e252f6243041d5985d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}